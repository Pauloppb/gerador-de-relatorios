# ğŸ§  Gerador AutomÃ¡tico de Relato de Atendimento

![Hospedado na Vercel](https://img.shields.io/badge/Hospedado%20na-Vercel-black?style=for-the-badge&logo=vercel)
![JavaScript](https://img.shields.io/badge/Javascript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)
![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)

Este projeto Ã© uma ferramenta web que utiliza **InteligÃªncia Artificial** para transformar transcriÃ§Ãµes de conversas de atendimento em relatÃ³rios estruturados e profissionais de forma instantÃ¢nea.

A aplicaÃ§Ã£o Ã© flexÃ­vel e moderna, permitindo escolher entre as **APIs da Google (Gemini)** ou da **Groq (Llama 3)** para a geraÃ§Ã£o dos relatÃ³rios.

---

## âœ¨ Funcionalidades

- **ğŸ§  GeraÃ§Ã£o AutomÃ¡tica:** Cole o texto da conversa e a IA gera um relatÃ³rio formatado e conciso, extraindo as informaÃ§Ãµes mais importantes.
- **ğŸ¨ Interface Limpa:** Design simples e direto ao ponto para mÃ¡xima eficiÃªncia e facilidade de uso.
- **âš¡ BotÃµes de AÃ§Ã£o RÃ¡pida:** Copiar ou Limpar os campos com apenas um clique.
- **ğŸ” Seguro:** A chave da API Ã© mantida de forma segura no backend, sem exposiÃ§Ã£o no navegador.
- **ğŸŒ Multi-Provider:** Suporte a mÃºltiplas APIs de IA (Gemini ou Groq), com seleÃ§Ã£o via variÃ¡vel de ambiente.

---

## ğŸ› ï¸ Tecnologias Utilizadas

Este projeto foi construÃ­do com uma arquitetura moderna e eficiente:

- **Frontend:** HTML5, CSS3, JavaScript (Vanilla JS)
- **Backend:** Node.js, implementado como uma funÃ§Ã£o serverless (ex: [Vercel Serverless Function](https://vercel.com/docs/functions))
- **APIs de IA:**
  - ğŸ§  **Google Gemini** â€“ `gemini-1.5-flash-latest`
  - ğŸ¦™ **Groq (LLaMA 3)** â€“ `llama3-8b-8192`
- **ğŸ“¦ EstratÃ©gia de Prompt:** ComunicaÃ§Ã£o com a IA feita por prompt estruturado com retorno em formato `JSON`, garantindo consistÃªncia e precisÃ£o no relatÃ³rio.
- **â˜ï¸ Hospedagem:** Vercel (ou outro serviÃ§o com suporte a funÃ§Ãµes serverless)

---

## ğŸš€ Como Rodar o Projeto

VocÃª pode rodar o projeto localmente ou hospedar com facilidade usando a [Vercel](https://vercel.com/):

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/Pauloppb/gerador-de-relatorios.git
cd gerador-de-relatorios
```

### 2. Instalar as DependÃªncias (caso necessÃ¡rio)

```bash
npm install
```

### 3. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env.local` com as suas chaves de API:

```env
GROQ_API_KEY=sua-chave-aqui
GEMINI_API_KEY=sua-chave-aqui
AI_PROVIDER=groq # ou gemini
```

### 4. Rodar Localmente

```bash
npm run dev
```

Acesse: `http://localhost:3000`

---

## ğŸ“Œ Exemplo de JSON Gerado

```json
{
  "relato_cliente": "Cliente informou que sua TV nÃ£o estava ligando.",
  "procedimentos_realizados": "Realizei o reinÃ­cio do sinal remotamente. Orientei a cliente a desligar o aparelho da tomada por 1 minuto como procedimento de teste.",
  "nome_cliente": "Maria",
  "telefone_cliente": "-",
  "protocolo_opa": "12345"
}
```

---

## ğŸ§‘â€ğŸ’» Autor

Desenvolvido por **Paulo Pereira** â€“ 2025  
Com o apoio das APIs **Google Gemini** e **Groq LLaMA 3**.